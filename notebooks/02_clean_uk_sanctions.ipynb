{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614a5153-1699-4727-8ddd-e49b0d7cf403",
   "metadata": {},
   "source": [
    "The goal of this notebook is to clean and standardize the raw UK Financial Sanctions dataset, preparing it for future name‑matching experiments.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "\n",
    "- **Preprocessing**: Selecting relevant columns and filtering the dataset\n",
    "\n",
    "- **Language Normalization**: Handling inconsistencies across Latin‑ and non‑Latin‑based names\n",
    "\n",
    "- **Name Cleaning**: Formatting names for consistency \n",
    "\n",
    "- **Outlier Analysis** Removing the top 1% of entities with too many names to reduce noise\n",
    "\n",
    "- **Data Aggregation** Creating a condensed version of the cleaned dataset, with a single row per entity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c6db7-31c7-4484-8fde-e632514258ff",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d40510-431c-4e7f-895a-329d5efc5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import warnings  \n",
    "from unidecode import unidecode\n",
    "import re   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#commands for better output readability \n",
    "pd.set_option('display.max_columns', None)  \n",
    "#pd.set_option('display.max_rows', None)  \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='pandas')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60a89c-3838-4da3-a228-1382118dcd8e",
   "metadata": {},
   "source": [
    "# 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa711231-95b5-411e-87c1-c48bfab6731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "project_dir=Path.cwd().parent\n",
    "raw_dir=project_dir/'data'/'raw'\n",
    "processed_dir=project_dir/'data'/'processed'\n",
    "processed_dir.mkdir(exist_ok=True)  #keep this just in case :/\n",
    "\n",
    "uk_file=raw_dir/'ConList.csv'\n",
    "\n",
    "df=pd.read_csv(uk_file,skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d2446-08e7-4bea-b0c8-6761a60b4240",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e914a98e-5148-45aa-82b7-e13f6f9f246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name 6</th>\n",
       "      <th>Name 1</th>\n",
       "      <th>Name 2</th>\n",
       "      <th>Name 3</th>\n",
       "      <th>Name 4</th>\n",
       "      <th>Name 5</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name Non-Latin Script</th>\n",
       "      <th>Non-Latin Script Type</th>\n",
       "      <th>Non-Latin Script Language</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Town of Birth</th>\n",
       "      <th>Country of Birth</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Passport Number</th>\n",
       "      <th>Passport Details</th>\n",
       "      <th>National Identification Number</th>\n",
       "      <th>National Identification Details</th>\n",
       "      <th>Position</th>\n",
       "      <th>Address 1</th>\n",
       "      <th>Address 2</th>\n",
       "      <th>Address 3</th>\n",
       "      <th>Address 4</th>\n",
       "      <th>Address 5</th>\n",
       "      <th>Address 6</th>\n",
       "      <th>Post/Zip Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Other Information</th>\n",
       "      <th>Group Type</th>\n",
       "      <th>Alias Type</th>\n",
       "      <th>Alias Quality</th>\n",
       "      <th>Regime</th>\n",
       "      <th>Listed On</th>\n",
       "      <th>UK Sanctions List Date Designated</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Group ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MITHOO</td>\n",
       "      <td>Mian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleric (“Pir”) of Bharchundi Sharif Shrine</td>\n",
       "      <td>Hafizabad Taluka Daharki</td>\n",
       "      <td>District Ghotki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>(UK Sanctions List Ref):GHR0086. (UK Statement...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Primary name variation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MITHU</td>\n",
       "      <td>Mian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleric (“Pir”) of Bharchundi Sharif Shrine</td>\n",
       "      <td>Hafizabad Taluka Daharki</td>\n",
       "      <td>District Ghotki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>(UK Sanctions List Ref):GHR0086. (UK Statement...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Primary name variation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MITTO</td>\n",
       "      <td>Mian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleric (“Pir”) of Bharchundi Sharif Shrine</td>\n",
       "      <td>Hafizabad Taluka Daharki</td>\n",
       "      <td>District Ghotki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>(UK Sanctions List Ref):GHR0086. (UK Statement...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Primary name variation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MITTU</td>\n",
       "      <td>Mian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleric (“Pir”) of Bharchundi Sharif Shrine</td>\n",
       "      <td>Hafizabad Taluka Daharki</td>\n",
       "      <td>District Ghotki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>(UK Sanctions List Ref):GHR0086. (UK Statement...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Primary name variation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZADACHIN</td>\n",
       "      <td>Andrei</td>\n",
       "      <td>Andreevich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22/08/1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1) Investigator for Particularly Important Ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(UK Sanctions List Ref):RUS1831. Financial san...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Primary name variation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russia</td>\n",
       "      <td>21/04/2023</td>\n",
       "      <td>21/04/2023</td>\n",
       "      <td>21/04/2023</td>\n",
       "      <td>15890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name 6  Name 1      Name 2 Name 3 Name 4 Name 5 Title  \\\n",
       "0    MITHOO    Mian         NaN    NaN    NaN    NaN   NaN   \n",
       "1     MITHU    Mian         NaN    NaN    NaN    NaN   NaN   \n",
       "2     MITTO    Mian         NaN    NaN    NaN    NaN   NaN   \n",
       "3     MITTU    Mian         NaN    NaN    NaN    NaN   NaN   \n",
       "4  ZADACHIN  Andrei  Andreevich    NaN    NaN    NaN   NaN   \n",
       "\n",
       "  Name Non-Latin Script Non-Latin Script Type Non-Latin Script Language  \\\n",
       "0                   NaN                   NaN                       NaN   \n",
       "1                   NaN                   NaN                       NaN   \n",
       "2                   NaN                   NaN                       NaN   \n",
       "3                   NaN                   NaN                       NaN   \n",
       "4                   NaN                   NaN                       NaN   \n",
       "\n",
       "          DOB Town of Birth Country of Birth Nationality Passport Number  \\\n",
       "0         NaN           NaN         Pakistan    Pakistan             NaN   \n",
       "1         NaN           NaN         Pakistan    Pakistan             NaN   \n",
       "2         NaN           NaN         Pakistan    Pakistan             NaN   \n",
       "3         NaN           NaN         Pakistan    Pakistan             NaN   \n",
       "4  22/08/1990           NaN           Russia      Russia             NaN   \n",
       "\n",
       "  Passport Details National Identification Number  \\\n",
       "0              NaN                            NaN   \n",
       "1              NaN                            NaN   \n",
       "2              NaN                            NaN   \n",
       "3              NaN                            NaN   \n",
       "4              NaN                            NaN   \n",
       "\n",
       "  National Identification Details  \\\n",
       "0                             NaN   \n",
       "1                             NaN   \n",
       "2                             NaN   \n",
       "3                             NaN   \n",
       "4                             NaN   \n",
       "\n",
       "                                            Position  \\\n",
       "0         Cleric (“Pir”) of Bharchundi Sharif Shrine   \n",
       "1         Cleric (“Pir”) of Bharchundi Sharif Shrine   \n",
       "2         Cleric (“Pir”) of Bharchundi Sharif Shrine   \n",
       "3         Cleric (“Pir”) of Bharchundi Sharif Shrine   \n",
       "4  (1) Investigator for Particularly Important Ca...   \n",
       "\n",
       "                  Address 1        Address 2 Address 3 Address 4 Address 5  \\\n",
       "0  Hafizabad Taluka Daharki  District Ghotki       NaN       NaN       NaN   \n",
       "1  Hafizabad Taluka Daharki  District Ghotki       NaN       NaN       NaN   \n",
       "2  Hafizabad Taluka Daharki  District Ghotki       NaN       NaN       NaN   \n",
       "3  Hafizabad Taluka Daharki  District Ghotki       NaN       NaN       NaN   \n",
       "4                       NaN              NaN       NaN       NaN       NaN   \n",
       "\n",
       "  Address 6 Post/Zip Code   Country  \\\n",
       "0       NaN           NaN  Pakistan   \n",
       "1       NaN           NaN  Pakistan   \n",
       "2       NaN           NaN  Pakistan   \n",
       "3       NaN           NaN  Pakistan   \n",
       "4       NaN           NaN       NaN   \n",
       "\n",
       "                                   Other Information  Group Type  \\\n",
       "0  (UK Sanctions List Ref):GHR0086. (UK Statement...  Individual   \n",
       "1  (UK Sanctions List Ref):GHR0086. (UK Statement...  Individual   \n",
       "2  (UK Sanctions List Ref):GHR0086. (UK Statement...  Individual   \n",
       "3  (UK Sanctions List Ref):GHR0086. (UK Statement...  Individual   \n",
       "4  (UK Sanctions List Ref):RUS1831. Financial san...  Individual   \n",
       "\n",
       "               Alias Type Alias Quality               Regime   Listed On  \\\n",
       "0  Primary name variation           NaN  Global Human Rights  09/12/2022   \n",
       "1  Primary name variation           NaN  Global Human Rights  09/12/2022   \n",
       "2  Primary name variation           NaN  Global Human Rights  09/12/2022   \n",
       "3  Primary name variation           NaN  Global Human Rights  09/12/2022   \n",
       "4  Primary name variation           NaN               Russia  21/04/2023   \n",
       "\n",
       "  UK Sanctions List Date Designated Last Updated  Group ID  \n",
       "0                        09/12/2022   09/12/2022     15672  \n",
       "1                        09/12/2022   09/12/2022     15672  \n",
       "2                        09/12/2022   09/12/2022     15672  \n",
       "3                        09/12/2022   09/12/2022     15672  \n",
       "4                        21/04/2023   21/04/2023     15890  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466b256d-5776-4bd9-a60c-74e1b3d8b532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Individual', 'Entity', 'Ship']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Group Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6c03c-9934-49df-9fc4-f9a934c40173",
   "metadata": {},
   "source": [
    "The raw dataset contains extensive information about each entity, including names, addresses, birthplaces, citizenship, and other details. Since this project focuses specifically on exploring name matching, the scope was narrowed down to the name fields and relevant sanction-related information. In addition, for consistency with the EU Sanctions Dataset, we only kept rows related to individuals and entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543d06ee-eec0-452c-bff0-db3854a22ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names=df[['Name 6','Name 1','Name 2','Name 3','Name 4','Name 5','Group Type','Regime','Last Updated','Group ID']]\n",
    "\n",
    "df_names=df_names[df_names['Group Type'] != 'Ship']\n",
    "\n",
    "df_names=df_names.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3a8979-f71d-4fd4-8674-e500687bf2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all name related columns were merged with the exception of the ones related to Non-latin Languages \n",
    "columns_to_merge=['Name 1','Name 2','Name 3','Name 4','Name 5','Name 6']\n",
    "\n",
    "def merge_names(row):\n",
    "    \"\"\"\n",
    "    Merges multiple name columns from a row into a single space-separated name.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row of a DataFrame containing columns listed in `columns_to_merge`.\n",
    "\n",
    "    Returns:\n",
    "        str: A combined name created by joining all non-null columns with a space.\n",
    "    \"\"\"\n",
    "    \n",
    "    row=row[columns_to_merge].dropna()\n",
    "    name=' '.join(row)\n",
    "    return name\n",
    "    \n",
    "#merge name columns in a single 'Name' cell\n",
    "df_names['Name']=df_names.apply(merge_names,axis=1)\n",
    "\n",
    "#drop the original columns and remove any rows with an empty 'Name' post-merge\n",
    "df_names=df_names.drop(columns=columns_to_merge)\n",
    "df_names=df_names.dropna(subset=['Name']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3692f-275f-4a70-b7c0-a79c45f3afb7",
   "metadata": {},
   "source": [
    "# 4. Language Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb8e38-7970-4bde-b3b4-baf63255abb0",
   "metadata": {},
   "source": [
    "Although rows with Non‑Latin were already filtered out, some names still contained special characters or diacritics. To standardize this we used `unidecode`, a library which intelligently maps non-ASCII Latin characters to their closest ASCII equivalents (e.g., ø → o, æ → ae, ç → c). More details about its limitations can be found at [Unidecode on PyPI](https://pypi.org/project/Unidecode/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c6e8395-40ea-485a-9f6c-fea7fd476e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by removing diacritics and special characters.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized text with diacritics and special characters removed.\n",
    "\n",
    "    Example:\n",
    "        >>> normalize('ołá')\n",
    "        'ola'\n",
    "    \"\"\"\n",
    "    return unidecode(text)\n",
    "\n",
    "df_names['Name']=df_names['Name'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e23c9-881f-4584-a9fb-621b89339119",
   "metadata": {},
   "source": [
    "# 5. Name Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cc917-a5ae-446b-b60a-7de5368d2175",
   "metadata": {},
   "source": [
    "After inspecting the names in the dataset, we noticed recurring inconsistencies in their formatting. To standardize them, we created two cleaning functions: `clean_name_individual`and `clean_name_entity`. Both functions apply the same text normalization and cleaning rules, differing only in their handling of numerical characters (relevant for entities). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e149b7-f379-4374-b366-51727e332da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name_individual(text):\n",
    "    \"\"\"\n",
    "    Cleans an individual's name using regex patterns.\n",
    "\n",
    "    Rules:\n",
    "    - Replaces apostrophes and hyphens with spaces\n",
    "    - Removes any character that is not a letter or space\n",
    "    - Capitalizes the first letter of each word\n",
    "\n",
    "    Args:\n",
    "        text (str): The raw name.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned, properly capitalized name.\n",
    "    \"\"\"\n",
    "    \n",
    "    text=re.sub(r\"[\\'\\-\\\\]\",' ',text)  \n",
    "    text=re.sub(r\"[^a-zA-Z\\s]\",'',text) \n",
    "    \n",
    "    text=text.split()\n",
    "    text=[word.capitalize() for word in text]  \n",
    "\n",
    "    text=' '.join(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#apply the cleaning function to 'Individual' rows\n",
    "df_names.loc[df_names['Group Type']=='Individual','Name']=df_names.loc[df_names['Group Type']=='Individual','Name'].apply(clean_name_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579761e0-4157-440f-a641-47b805bd22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name_entity(text):\n",
    "    \"\"\"\n",
    "    Cleans an entity's name using regex patterns and standardizes common suffixes.\n",
    "\n",
    "    Rules:\n",
    "    - Replaces apostrophes and hyphens with spaces\n",
    "    - Removes any character that is not a letter, digit, or space\n",
    "    - Standardizes common suffixes ( Llp -> LLP, Limited -> Ltd, Company -> Co)\n",
    "    - Capitalizes the first letter of each word\n",
    "\n",
    "    Args:\n",
    "        text (str): The raw entity name.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned, properly formatted entity name.\n",
    "    \"\"\"\n",
    "    \n",
    "    text=re.sub(r\"[\\'\\-\\\\]\",' ',text)  \n",
    "    text=re.sub(r\"[^a-zA-Z0-9\\s]\",'',text) \n",
    "\n",
    "    text=re.sub(r\"\\bLlp\\b\", \"LLP\", text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r\"\\bLtd\\b\", \"Ltd\", text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r\"\\bLimited\\b\", \"Ltd\", text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r\"\\bCo\\b\", \"Co\", text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r\"\\bCompany\\b\", \"Co\", text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r\"\\bInc\\b\", \"Inc\", text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r\"\\bIncorporated\\b\", \"Inc\", text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r\"\\bOjsc\\b\", \"OJSC\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    text=text.split()\n",
    "    text=[word.capitalize() for word in text]  \n",
    "\n",
    "    text=' '.join(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#apply the cleaning function to 'Entity' rows\n",
    "df_names.loc[df_names['Group Type']=='Entity','Name']=df_names.loc[df_names['Group Type']=='Entity','Name'].apply(clean_name_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd8a117-c2a9-4c26-8b9e-618d7e1c5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just in case to avoid errors\n",
    "df_names=df_names.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43f1ec8-ae19-453e-8988-58e87c8318aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Type</th>\n",
       "      <th>Regime</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Group ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Individual</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "      <td>Mian Mithoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Individual</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "      <td>Mian Mithu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Individual</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "      <td>Mian Mitto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Individual</td>\n",
       "      <td>Global Human Rights</td>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>15672</td>\n",
       "      <td>Mian Mittu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Individual</td>\n",
       "      <td>Russia</td>\n",
       "      <td>21/04/2023</td>\n",
       "      <td>15890</td>\n",
       "      <td>Andrei Andreevich Zadachin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group Type               Regime Last Updated  Group ID  \\\n",
       "0  Individual  Global Human Rights   09/12/2022     15672   \n",
       "1  Individual  Global Human Rights   09/12/2022     15672   \n",
       "2  Individual  Global Human Rights   09/12/2022     15672   \n",
       "3  Individual  Global Human Rights   09/12/2022     15672   \n",
       "4  Individual               Russia   21/04/2023     15890   \n",
       "\n",
       "                         Name  \n",
       "0                 Mian Mithoo  \n",
       "1                  Mian Mithu  \n",
       "2                  Mian Mitto  \n",
       "3                  Mian Mittu  \n",
       "4  Andrei Andreevich Zadachin  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6a389-4829-47ac-b1f2-8838071c9625",
   "metadata": {},
   "source": [
    "# 6. Outlier Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06364c2-8211-4547-980f-dc4fe89bce5b",
   "metadata": {},
   "source": [
    "Names associated with the same entity can vary significantly, from a handful of entries to 100+. To prevent disproportionately long or ambiguous records from affecting the quality of name matching, we identified and removed outliers:\n",
    "\n",
    "- We first group names by entity ID and count how many names each entity had.\n",
    "\n",
    "- We observed a highly skewed distribution, with certain entities having an unusually high number of names.\n",
    "\n",
    "- To formalize the cutoff, we computed the 99th percentile of counts for people and enterprises:\n",
    "\n",
    "- All entities with counts above these thresholds were treated as outliers and removed from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "480bd61b-8446-4955-a09d-e1b382e79f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Group ID  Count\n",
      "910      12771    144\n",
      "392      10638    108\n",
      "988      12896     81\n",
      "1975     14068     57\n",
      "985      12892     49\n",
      "...        ...    ...\n",
      "4619     16796      1\n",
      "4620     16797      1\n",
      "4621     16798      1\n",
      "4625     16802      1\n",
      "4634     16811      1\n",
      "\n",
      "[4651 rows x 2 columns]\n",
      "      Group ID  Count\n",
      "33        7241     27\n",
      "265      12981     27\n",
      "965      16718     19\n",
      "106      11090     18\n",
      "129      11241     18\n",
      "...        ...    ...\n",
      "1002     16812      1\n",
      "996      16798      1\n",
      "995      16794      1\n",
      "994      16792      1\n",
      "992      16790      1\n",
      "\n",
      "[1008 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#print Name Counts per ID\n",
    "\n",
    "individual_counts=df_names.groupby('Group ID').size().reset_index(name='Count')\n",
    "entity_counts= df_names[df_names['Group Type']=='Entity'].groupby('Group ID').size().reset_index(name='Count')\n",
    "\n",
    "individual_counts=individual_counts.sort_values(by='Count',ascending=False)\n",
    "entity_counts=entity_counts.sort_values(by='Count',ascending=False)\n",
    "\n",
    "print(individual_counts)\n",
    "print(entity_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4fb3147-5119-4391-ba94-70995b27c174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper limit for Individuals: 16.0\n",
      "Upper limit for Entities: 13.0\n"
     ]
    }
   ],
   "source": [
    "#print 99th percentile name count\n",
    "\n",
    "x_i=individual_counts['Count']\n",
    "x_e=entity_counts['Count']\n",
    "\n",
    "upper_i_new=np.percentile(x_i, 99) \n",
    "upper_e_new=np.round(np.percentile(x_e, 99),1)  \n",
    "\n",
    "print('Upper limit for Individuals:',upper_i_new)\n",
    "print('Upper limit for Entities:',upper_e_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0f3f764-0e48-4780-9b77-25b7c425549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers from dataset\n",
    "outliers_individual=individual_counts[individual_counts['Count']>upper_i_new].reset_index(drop=True)\n",
    "outliers_entity=entity_counts[entity_counts['Count']>upper_e_new].reset_index(drop=True)\n",
    "\n",
    "outliers_ID=pd.concat([outliers_individual['Group ID'], outliers_entity['Group ID']], ignore_index=True)\n",
    "df_names=df_names[~df_names['Group ID'].isin(outliers_ID)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39006474-f4cc-4098-85f6-6af86e0106ef",
   "metadata": {},
   "source": [
    "# 7. Data Aggregation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba93f6-3598-4d9c-a494-0f8789e5d6f7",
   "metadata": {},
   "source": [
    "For future experiments, we created a condensed version of the dataset, `df_grouped`, by aggregating all names associated with a single ID into a single cell. This approach will potentially allow for more efficient processing and matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc155a2f-33b9-40c2-b34b-96983879cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped=df_names.copy()\n",
    "\n",
    "def aggregate_unique_words(grouped_names):\n",
    "    \"\"\"\n",
    "\n",
    "    This function takes a list of names, splits each name into its individual words,\n",
    "    and returns a comma-separated string of all unique words across the list.\n",
    "\n",
    "    Args:\n",
    "        grouped_names (list of str): List of names associated with a single entity.\n",
    "\n",
    "    Returns:\n",
    "        str: A comma-separated string of unique words extracted from the names.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    words=set()\n",
    "\n",
    "    for name in grouped_names:\n",
    "\n",
    "        name=name.split()\n",
    "        words.update(name)\n",
    "        \n",
    "    return ', '.join(words)\n",
    "\n",
    "            \n",
    "df_grouped=df_grouped.groupby('Group ID',as_index=False).agg({\n",
    "       \n",
    "    'Group Type':'first',\n",
    "    'Regime': 'first',         \n",
    "    'Last Updated': 'first',\n",
    "    'Name': aggregate_unique_words,  \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41b09c-b655-4b68-909f-d6134f3dcf18",
   "metadata": {},
   "source": [
    "# 8. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f8db3fd-409d-439b-8f8a-19146a533cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11339 entries, 0 to 11338\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Group Type    11339 non-null  object\n",
      " 1   Regime        11339 non-null  object\n",
      " 2   Last Updated  11339 non-null  object\n",
      " 3   Group ID      11339 non-null  int64 \n",
      " 4   Name          11339 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 443.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_names.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd71914f-77d8-4681-87ce-f6e8ef0f547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4606 entries, 0 to 4605\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Group ID      4606 non-null   int64 \n",
      " 1   Group Type    4606 non-null   object\n",
      " 2   Regime        4606 non-null   object\n",
      " 3   Last Updated  4606 non-null   object\n",
      " 4   Name          4606 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 180.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca0e8a4-1057-4346-9629-5ddc24ff8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.to_csv(processed_dir/'cleaned_uk_sanctions.csv', index=False)\n",
    "df_grouped.to_csv(processed_dir/'cleaned_uk_sanctions_grouped.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
